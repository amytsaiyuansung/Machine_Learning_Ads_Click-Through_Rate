{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# plot\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "# def functions\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv('ProjectTestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13015341, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test\n",
    "Test['date'] = round((Test.hour - 14100000)/100).astype('int')\n",
    "Test.hour = Test.hour - 14100000 - Test.date * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = Test.iloc[:, 1:].copy() # delete id\n",
    "X_Test.drop(['device_id', 'device_ip'], axis = 1, inplace = True) # so many categories, drop these two variables for now\n",
    "\n",
    "# for date 30, date 31\n",
    "X_Test.loc[X_Test.date == 30, 'date'] = 30 - 7\n",
    "X_Test.loc[X_Test.date == 31, 'date'] = 31 - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_26 = pd.read_csv('Train-026.csv', header = None)\n",
    "Train_27 = pd.read_csv('Train-027.csv', header = None)\n",
    "Train_28 = pd.read_csv('Train-028.csv', header = None)\n",
    "Train_29 = pd.read_csv('Train-029.csv', header = None)\n",
    "Train_30 = pd.read_csv('Train-030.csv', header = None)\n",
    "\n",
    "Train_26.columns = ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
    "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
    "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
    "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "Train_27.columns = ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
    "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
    "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
    "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "Train_28.columns = ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
    "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
    "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
    "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "Train_29.columns = ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
    "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
    "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
    "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "Train_30.columns = ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
    "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
    "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
    "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']\n",
    "\n",
    "# For Train\n",
    "\n",
    "Train_26['date'] = round((Train_26.hour - 14100000)/100).astype('int')\n",
    "Train_26.hour = Train_26.hour - 14100000 - Train_26.date * 100\n",
    "for i in range(2, 25):\n",
    "        Train_26.iloc[:, i] = Train_26.iloc[:, i].astype('category') # change to categorical variables\n",
    "Train_26 = Train_26.iloc[:, 1:] # delete id\n",
    "\n",
    "# for cat_var in Train_26.columns:\n",
    "#     print(cat_var, Train_26[cat_var].nunique())\n",
    "Train_26.drop(['device_id', 'device_ip'], axis = 1, inplace = True) # so many categories, drop these two variables for now\n",
    "\n",
    "Train_27['date'] = round((Train_27.hour - 14100000)/100).astype('int')\n",
    "Train_27.hour = Train_27.hour - 14100000 - Train_27.date * 100\n",
    "for i in range(2, 25):\n",
    "        Train_27.iloc[:, i] = Train_27.iloc[:, i].astype('category') # change to categorical variables\n",
    "Train_27 = Train_27.iloc[:, 1:] # delete id\n",
    "\n",
    "# for cat_var in Train_27.columns:\n",
    "#     print(cat_var, Train_27[cat_var].nunique())\n",
    "Train_27.drop(['device_id', 'device_ip'], axis = 1, inplace = True) # so many categories, drop these two variables for now\n",
    "\n",
    "Train_28['date'] = round((Train_28.hour - 14100000)/100).astype('int')\n",
    "Train_28.hour = Train_28.hour - 14100000 - Train_28.date * 100\n",
    "for i in range(2, 25):\n",
    "        Train_28.iloc[:, i] = Train_28.iloc[:, i].astype('category') # change to categorical variables\n",
    "Train_28 = Train_28.iloc[:, 1:] # delete id\n",
    "\n",
    "# for cat_var in Train_28.columns:\n",
    "#     print(cat_var, Train_28[cat_var].nunique())\n",
    "Train_28.drop(['device_id', 'device_ip'], axis = 1, inplace = True) # so many categories, drop these two variables for now\n",
    "\n",
    "Train_29['date'] = round((Train_29.hour - 14100000)/100).astype('int')\n",
    "Train_29.hour = Train_29.hour - 14100000 - Train_29.date * 100\n",
    "for i in range(2, 25):\n",
    "        Train_29.iloc[:, i] = Train_29.iloc[:, i].astype('category') # change to categorical variables\n",
    "Train_29 = Train_29.iloc[:, 1:] # delete id\n",
    "\n",
    "# for cat_var in Train_29.columns:\n",
    "#     print(cat_var, Train_29[cat_var].nunique())\n",
    "Train_29.drop(['device_id', 'device_ip'], axis = 1, inplace = True) # so many categories, drop these two variables for now\n",
    "\n",
    "Train_30['hour'] = Train_30['hour'].astype('int')\n",
    "Train_30['date'] = round((Train_30.hour - 14100000)/100).astype('int')\n",
    "Train_30.hour = Train_30.hour - 14100000 - Train_30.date * 100\n",
    "for i in range(2, 25):\n",
    "        Train_30.iloc[:, i] = Train_30.iloc[:, i].astype('category') # change to categorical variables\n",
    "Train_30 = Train_30.iloc[:, 1:] # delete id\n",
    "\n",
    "# for cat_var in Train_10.columns:\n",
    "#     print(cat_var, Train_10[cat_var].nunique())\n",
    "Train_30.drop(['device_id', 'device_ip'], axis = 1, inplace = True) # so many categories, drop these two variables for now\n",
    "\n",
    "X_train_26 = Train_26.iloc[:,1:]\n",
    "y_train_26 = Train_26['click']\n",
    "\n",
    "X_train_27 = Train_27.iloc[:,1:]\n",
    "y_train_27 = Train_27['click']\n",
    "\n",
    "X_train_28 = Train_28.iloc[:,1:]\n",
    "y_train_28 = Train_28['click']\n",
    "\n",
    "X_train_29 = Train_29.iloc[:,1:]\n",
    "y_train_29 = Train_29['click']\n",
    "\n",
    "X_train_30 = Train_30.iloc[:,1:]\n",
    "y_train_30 = Train_30['click']\n",
    "\n",
    "X_train_tree_26 = pd.DataFrame(X_train_26.values).copy()\n",
    "X_Test_tree_26 = pd.DataFrame(X_Test.values).copy()\n",
    "\n",
    "X_26 = pd.concat([X_train_tree_26, X_Test_tree_26])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "les = []\n",
    "\n",
    "for i in range(X_train_tree_26.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(X_26.iloc[:, i])\n",
    "    les.append(le)\n",
    "    X_train_tree_26.iloc[:, i] = le.transform(X_train_tree_26.iloc[:, i])\n",
    "    X_Test_tree_26.iloc[:, i] = le.transform(X_Test_tree_26.iloc[:, i])\n",
    "\n",
    "X_train_tree_27 = pd.DataFrame(X_train_27.values).copy()\n",
    "X_Test_tree_27 = pd.DataFrame(X_Test.values).copy()\n",
    "\n",
    "X_27 = pd.concat([X_train_tree_27, X_Test_tree_27])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "les = []\n",
    "\n",
    "for i in range(X_train_tree_27.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(X_27.iloc[:, i])\n",
    "    les.append(le)\n",
    "    X_train_tree_27.iloc[:, i] = le.transform(X_train_tree_27.iloc[:, i])\n",
    "    X_Test_tree_27.iloc[:, i] = le.transform(X_Test_tree_27.iloc[:, i])\n",
    "\n",
    "X_train_tree_28 = pd.DataFrame(X_train_28.values).copy()\n",
    "X_Test_tree_28 = pd.DataFrame(X_Test.values).copy()\n",
    "\n",
    "X_28 = pd.concat([X_train_tree_28, X_Test_tree_28])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "les = []\n",
    "\n",
    "for i in range(X_train_tree_28.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(X_28.iloc[:, i])\n",
    "    les.append(le)\n",
    "    X_train_tree_28.iloc[:, i] = le.transform(X_train_tree_28.iloc[:, i])\n",
    "    X_Test_tree_28.iloc[:, i] = le.transform(X_Test_tree_28.iloc[:, i])\n",
    "\n",
    "X_train_tree_29 = pd.DataFrame(X_train_29.values).copy()\n",
    "X_Test_tree_29 = pd.DataFrame(X_Test.values).copy()\n",
    "\n",
    "X_29 = pd.concat([X_train_tree_29, X_Test_tree_29])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "les = []\n",
    "\n",
    "for i in range(X_train_tree_29.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(X_29.iloc[:, i])\n",
    "    les.append(le)\n",
    "    X_train_tree_29.iloc[:, i] = le.transform(X_train_tree_29.iloc[:, i])\n",
    "    X_Test_tree_29.iloc[:, i] = le.transform(X_Test_tree_29.iloc[:, i])\n",
    "    \n",
    "X_train_tree_30 = pd.DataFrame(X_train_30.values).copy()\n",
    "X_Test_tree_30 = pd.DataFrame(X_Test.values).copy()\n",
    "\n",
    "X_30 = pd.concat([X_train_tree_30, X_Test_tree_30])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "les = []\n",
    "\n",
    "for i in range(X_train_tree_30.shape[1]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(X_30.iloc[:, i])\n",
    "    les.append(le)\n",
    "    X_train_tree_30.iloc[:, i] = le.transform(X_train_tree_30.iloc[:, i])\n",
    "    X_Test_tree_30.iloc[:, i] = le.transform(X_Test_tree_30.iloc[:, i])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForest = RandomForestClassifier(max_depth = 20, n_estimators = 25, min_samples_split = 150, max_features=0.3)\n",
    "\n",
    "np.random.seed(613)\n",
    "randomForest.fit(X_train_tree_26, y_train_26)\n",
    "\n",
    "y_pred_26 = randomForest.predict(X_Test_tree_26)\n",
    "y_pred_26_prob = randomForest.predict_proba(X_Test_tree_26)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForest = RandomForestClassifier(max_depth = 20, n_estimators = 25, min_samples_split = 150, max_features=0.3)\n",
    "\n",
    "np.random.seed(613)\n",
    "randomForest.fit(X_train_tree_27, y_train_27)\n",
    "\n",
    "y_pred_27 = randomForest.predict(X_Test_tree_27)\n",
    "y_pred_27_prob = randomForest.predict_proba(X_Test_tree_27)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForest = RandomForestClassifier(max_depth = 20, n_estimators = 25, min_samples_split = 150, max_features=0.3)\n",
    "\n",
    "np.random.seed(613)\n",
    "randomForest.fit(X_train_tree_28, y_train_28)\n",
    "\n",
    "y_pred_28 = randomForest.predict(X_Test_tree_28)\n",
    "y_pred_28_prob = randomForest.predict_proba(X_Test_tree_28)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForest = RandomForestClassifier(max_depth = 20, n_estimators = 25, min_samples_split = 150, max_features=0.3)\n",
    "\n",
    "np.random.seed(613)\n",
    "randomForest.fit(X_train_tree_29, y_train_29)\n",
    "\n",
    "y_pred_29 = randomForest.predict(X_Test_tree_29)\n",
    "y_pred_29_prob = randomForest.predict_proba(X_Test_tree_29)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForest = RandomForestClassifier(max_depth = 20, n_estimators = 25, min_samples_split = 150, max_features=0.3)\n",
    "\n",
    "np.random.seed(613)\n",
    "randomForest.fit(X_train_tree_30, y_train_30)\n",
    "\n",
    "y_pred_30 = randomForest.predict(X_Test_tree_30)\n",
    "y_pred_30_prob = randomForest.predict_proba(X_Test_tree_30)\n",
    "\n",
    "pd.DataFrame(y_pred_26_prob[:,1]).to_csv('y_rf_final_pred_26.csv', index = False, header = False)\n",
    "pd.DataFrame(y_pred_27_prob[:,1]).to_csv('y_rf_final_pred_27.csv', index = False, header = False)\n",
    "pd.DataFrame(y_pred_28_prob[:,1]).to_csv('y_rf_final_pred_28.csv', index = False, header = False)\n",
    "pd.DataFrame(y_pred_29_prob[:,1]).to_csv('y_rf_final_pred_29.csv', index = False, header = False)\n",
    "pd.DataFrame(y_pred_30_prob[:,1]).to_csv('y_rf_final_pred_30.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_00_prob = pd.read_csv('y_rf_final_pred_00.csv', header = None)\n",
    "y_pred_01_prob = pd.read_csv('y_rf_final_pred_01.csv', header = None)\n",
    "y_pred_02_prob = pd.read_csv('y_rf_final_pred_02.csv', header = None)\n",
    "y_pred_03_prob = pd.read_csv('y_rf_final_pred_03.csv', header = None)\n",
    "y_pred_04_prob = pd.read_csv('y_rf_final_pred_04.csv', header = None)\n",
    "y_pred_05_prob = pd.read_csv('y_rf_final_pred_05.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_1 = y_pred_00_prob + y_pred_01_prob + y_pred_02_prob + y_pred_03_prob + y_pred_04_prob + y_pred_05_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_pred_00_prob\n",
    "del y_pred_01_prob\n",
    "del y_pred_02_prob\n",
    "del y_pred_03_prob\n",
    "del y_pred_04_prob\n",
    "del y_pred_05_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_06_prob = pd.read_csv('y_rf_final_pred_06.csv', header = None)\n",
    "y_pred_07_prob = pd.read_csv('y_rf_final_pred_07.csv', header = None)\n",
    "y_pred_08_prob = pd.read_csv('y_rf_final_pred_08.csv', header = None)\n",
    "y_pred_09_prob = pd.read_csv('y_rf_final_pred_09.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_2 = y_pred_06_prob + y_pred_07_prob + y_pred_08_prob + y_pred_09_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_pred_06_prob\n",
    "del y_pred_07_prob\n",
    "del y_pred_08_prob\n",
    "del y_pred_09_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_11_prob = pd.read_csv('y_rf_final_pred_11.csv', header = None)\n",
    "y_pred_12_prob = pd.read_csv('y_rf_final_pred_12.csv', header = None)\n",
    "y_pred_13_prob = pd.read_csv('y_rf_final_pred_13.csv', header = None)\n",
    "y_pred_14_prob = pd.read_csv('y_rf_final_pred_14.csv', header = None)\n",
    "y_pred_15_prob = pd.read_csv('y_rf_final_pred_15.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_3 = y_pred_11_prob + y_pred_12_prob + y_pred_13_prob + y_pred_14_prob + y_pred_15_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_pred_11_prob\n",
    "del y_pred_12_prob\n",
    "del y_pred_13_prob\n",
    "del y_pred_14_prob\n",
    "del y_pred_15_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_16_prob = pd.read_csv('y_rf_final_pred_16.csv', header = None)\n",
    "y_pred_17_prob = pd.read_csv('y_rf_final_pred_17.csv', header = None)\n",
    "y_pred_18_prob = pd.read_csv('y_rf_final_pred_18.csv', header = None)\n",
    "y_pred_19_prob = pd.read_csv('y_rf_final_pred_19.csv', header = None)\n",
    "y_pred_20_prob = pd.read_csv('y_rf_final_pred_20.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_4 = y_pred_16_prob + y_pred_17_prob + y_pred_18_prob + y_pred_19_prob + y_pred_20_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_pred_16_prob\n",
    "del y_pred_17_prob\n",
    "del y_pred_18_prob\n",
    "del y_pred_19_prob\n",
    "del y_pred_20_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_21_prob = pd.read_csv('y_rf_final_pred_21.csv', header = None)\n",
    "y_pred_22_prob = pd.read_csv('y_rf_final_pred_22.csv', header = None)\n",
    "y_pred_23_prob = pd.read_csv('y_rf_final_pred_23.csv', header = None)\n",
    "y_pred_24_prob = pd.read_csv('y_rf_final_pred_24.csv', header = None)\n",
    "y_pred_25_prob = pd.read_csv('y_rf_final_pred_25.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_5 = y_pred_21_prob + y_pred_22_prob + y_pred_23_prob + y_pred_24_prob + y_pred_25_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_pred_21_prob\n",
    "del y_pred_22_prob\n",
    "del y_pred_23_prob\n",
    "del y_pred_24_prob\n",
    "del y_pred_25_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_26_prob = pd.read_csv('y_rf_final_pred_26.csv', header = None)\n",
    "y_pred_27_prob = pd.read_csv('y_rf_final_pred_27.csv', header = None)\n",
    "y_pred_28_prob = pd.read_csv('y_rf_final_pred_28.csv', header = None)\n",
    "y_pred_29_prob = pd.read_csv('y_rf_final_pred_29.csv', header = None)\n",
    "y_pred_30_prob = pd.read_csv('y_rf_final_pred_30.csv', header = None)\n",
    "y_pred_31_prob = pd.read_csv('y_rf_final_pred_31.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_6 = y_pred_26_prob + y_pred_27_prob + y_pred_28_prob + y_pred_29_prob + y_pred_30_prob + y_pred_31_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_pred_26_prob\n",
    "del y_pred_27_prob\n",
    "del y_pred_28_prob\n",
    "del y_pred_29_prob\n",
    "del y_pred_30_prob\n",
    "del y_pred_31_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = (chunk_1 + chunk_2 + chunk_3 + chunk_4 + chunk_5 + chunk_6)/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = pd.concat([Test['id'], final_predictions], axis = 1)\n",
    "submission = pd.read_csv('ProjectSubmission-Team3.csv')\n",
    "submission.drop('P(click)', axis = 1, inplace = True)\n",
    "submission = pd.merge(submission, final_predictions, on = 'id', how = 'inner')\n",
    "submission.columns[[1]]\n",
    "submission.columns = ['id', 'P(click)']\n",
    "submission.to_csv('ProjectSubmission-Team3.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
